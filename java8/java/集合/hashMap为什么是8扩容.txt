1、为什么要扩容两倍，而不是1.5倍 1倍？
它通过h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。

2、为什么是链表长度大于8时转成红黑树，为什么长度小于等于6回退成链表？
链表平均复杂度是n/2，红黑树是log2n。log2n<n/2，解出n＝8
还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。
假设一下，如果设计成链表个数超过8则链表转换成树结构，
链表个数小于8则树结构转换成链表，
如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。



3、扩容机制可能会带来哪些问题，那么怎么样做可以减少扩容
当hashMap中的节点数超过阈值的时候，就会自动扩容，扩容的时候就会调整hashMap的大小，一旦调整了hashMap的大小就会导致之前的hashCode计算出来的hash表中下标无效，所以所有的节点都需要重新hash运算，结果就是带来时间上的浪费。因此我们要尽量避免hashMap调整大小，所以我们使用hashMap的时候要给hashMap设置一个默认值，这个默认值要大于我们hashMap中存放的节点数



4、线程不安全resize的时候可能会导致死循环
当重新调整HashMap大小的时候，确实存在条件竞争，因为如果两个线程都发现HashMap需要重新调整大小了，它们会同时试着调整大小。在调整大小的过程中，存储在LinkedList中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在LinkedList的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了


